<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Work Experience</title>
    <link rel="stylesheet" href="/styles.css">
    <script defer src="/scripts/loadComponents.js"></script>
</head>
<body>
    <div id="nav-placeholder"></div>
    <header class="hidden">
        <h1>Work Experience</h1>
    </header>
    <main>
        <!-- Intro Section -->
        <section class="work-intro">
            <h2>Building Bridges, Crafting Solutions</h2>
            <img src="/images/profile.jfif" alt="Profile Picture" style="border-radius: 50%; width: 150px; margin-bottom: 20px;">
            <p>I am a driven engineer with a passion for problem solving, with experience from multiple successful project deliveries in analytics and operations. With Machine Learning experience in various areas including Computer Vision and NLP, I have progressively widened my scope to include data engineering higher up the data chain and MLOps surrounding Machine Learning. I enjoy taking ownership of challenging projects and pushing them across the finish line, which I have been able to do in industries such as healthcare, transportation, construction, and retail. I excel at decomposing complex problems into easier to understand sub-problems and communicating effectively across teams. I also practice this decomposition and communication in my free time, where I have been teaching salsa classes for over 3 years.</p>
        </section>

        <!-- Three Columns Section -->
        <section class="three-columns">
            <div class="column roles">
                <h3>Roles</h3>
                <ul>
                    <li>Data Engineer</li>
                    <li>ML Engineer</li>
                    <li>Data Scientist</li>
                    <li>MLOps Engineer</li>
                    <li>Project Manager</li>
                </ul>
            </div>
            <div class="column areas">
                <h3>Areas</h3>
                <ul>
                    <li>Healthcare</li>
                    <li>Transportation</li>
                    <li>Construction</li>
                    <li>Retail</li>
                </ul>
            </div>
            <div class="column">
                <h3>Competences</h3>
                <div class="competences">
                    <ul>
                        <li>Python</li>
                        <li>PySpark</li>
                        <li>PyTorch</li>
                        <li>TensorFlow</li>
                        <li>SQL</li>
                        <li>R</li>
                        <li>Azure</li>
                        <li>AWS</li>
                        <li>Databricks</li>
                    </ul>
                    <ul>
                        <li>Docker</li>
                        <li>Computer Vision</li>
                        <li>Time Series Forecasting</li>
                        <li>NLP</li>
                        <li>CI/CD</li>
                        <li>MLOps</li>
                        <li>IaC</li>
                        <li>ETL</li>
                        <li>Terraform</li>
                        <li>Git</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Work History Section -->
        <section class="work-history">
            <h2>Work History</h2>
            
            <!-- Consultant, CGI (2022-2024) -->
            <div class="job">
                <h3>Consultant, CGI (2022-2024)</h3>
                
                <!-- Recognition Highlight -->
                <div class="recognition-highlight">
                    <span class="award-icon">üèÜ</span>
                    <p>Recognized as the <strong>Advanced Analytics Solutions Knowledge Sharing Presenter of the Year</strong>. 
                        <a href="https://www.linkedin.com/feed/update/urn:li:activity:7257095982675337216/" target="_blank">Read more ‚Üí</a>
                    </p>
                </div>

                <div class="recognition-highlight">
                    <span class="award-icon">üì∞</span>
                    <p>Featured in CGI's blog highlighting my journey in AI, data engineering, and teaching salsa. 
                        <a href="https://www.cgi.com/fi/fi/blogi/cginside/ai-data-engineers-super-skills-salsa-and-joy-learning" target="_blank">Read more ‚Üí</a>
                    </p>
                </div>

                <!-- Project 1: Data Engineer ‚Äì Unified Data Platform -->
                <div class="project">
                    <h4>Data Engineer ‚Äì Unified Data Platform</h4>
                    <p><strong>Company:</strong> A Multinational retail company</p>
                    <p><strong>Dates:</strong> Q1 2024 ‚Äì Q3 2024</p>
                    <p>The client is a multinational retail company focusing on household appliances. They operate in more than 60 countries across the world, employ over 9000 people and have an annual revenue of over three billion euro. They also work with approximately 100,000 independent sales partners.</p>
                    <p>The client has customer, sales partner and employee data spread across many different databases, including SAP systems and an on-premise data center. They want to have a unified single source of truth for this data. They have two existing solutions in different countries, one using an ‚Äòout-of-the-box‚Äô SAP solution that has a costly license and is very limiting for future applications, and one using data mart that requires a total of 48 hours for source data to propagate to the business level. Additionally, they want this consolidated data to be able to source future analytics and AI projects.</p>
                    <p>I was part of a small team tasked to develop a proof-of-concept within one month. Under a tight deadline, we were able to demonstrate the feasibility and potential of our solution. 
                        After the Proof of Concept, I took the lead in the data processing with Databricks using PySpark and worked on developping the ingestion pipelines using Azure Data Factory.
                        After a successful deployment in the first country, the same solution is now being deployed in at least two additional countries.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>Databricks</span>
                        <span>Azure Data Factory</span>
                        <span>AzureSQL</span>
                        <span>Data Platform</span>
                        <span>ETL</span>
                        <span>Data Modelling</span>
                        <span>Medallion Architecture</span>
                        <span>PySpark</span>
                        <span>SQL</span>
                    </div>
                </div>
                
                <!-- Project 2: MLOps Engineer ‚Äì Machine Learning Platform -->
                <div class="project">
                    <h4>MLOps Engineer ‚Äì Machine Learning Platform</h4>
                    <p><strong>Company:</strong> A Public Transport Company</p>
                    <p><strong>Dates:</strong> Q2 2023 - Q4 2023</p>
                    <p>The client is a transport company that maintains a public transportation network, which includes buses, trams, metro, and commuter trains. They employ 400 people.</p>
                    <p>The client wants to use data to determine which are the optimal frequencies for each transit route to service the users in the best way possible. To that end, they want to track the number of passengers on each vehicle to determine whether a route at a point in time is over- or under-utilized, and adapt the offering accordingly. They have collected this data, however; the quality is very low, and there is a lot of missing data. They want to impute the missing data in an intelligent way so this data can be an accurate source for decision making.</p>
                    <p>I worked as an MLOps Engineer, taking on several responsibilities within the project. 
                        I implemented CI/CD pipelines in Azure Pipelines to automate the model deployment process. 
                        The model versioning and monitoring in Azure Machine Learning was also taken care of by me, as well as the model packaging in Docker containers stored in Azure Container Registry to ensure consistent deployments. 
                        Additionally, I assisted the client's data science team with the data preprocessing and modelling. 
                        My input was highly valued as the leading voice on all cloud related matters within the project, as well as strategic insight for future improvements.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>Azure Machine Learning</span>
                        <span>Azure Pipelines</span>
                        <span>Azure DevOps</span>
                        <span>Docker</span>
                        <span>Azure Container Registry</span>
                        <span>Python</span>
                        <span>R</span>
                    </div>
                </div>

                <!-- Project 3: Machine Learning Engineer ‚Äì Emergency Medical Care -->
                <div class="project">
                    <h4>Machine Learning Engineer ‚Äì Emergency Medical Care</h4>
                    <p><strong>Company:</strong> A Healthcare Provider</p>
                    <p><strong>Dates:</strong> Q4 2022 ‚Äì Q1 2023</p>
                    <p>The client is one of the largest hospital networks in Europe, employing over 26 thousand employees.</p>
                    <p>The client wants to determine the optimal locations across the city to station their ambulances to minimize the response time. 
                        A simulation tool was developed using Azure Functions to test multiple configurations, as well as an ensemble model using scikit-learn to generate the optimal locations.</p>
                    <p>I worked on the data preprocessing and refactoring of the code, cleaning up the code and documentation. 
                        I also rewrote the preprocessing from R to Python, increasing the maintainability of the codebase and speeding up the preprocessing step.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>Optimization</span>
                        <span>Preprocessing</span>
                        <span>Azure Functions</span>
                        <span>Scikit-Learn</span>
                        <span>R</span>
                        <span>Python</span>
                    </div>
                </div>

                <!-- Project 4: Data Scientist ‚Äì Time Series Forecasting -->
                <div class="project">
                    <h4>Data Scientist ‚Äì Time Series Forecasting</h4>
                    <p><strong>Company:</strong> A Construction and Development Company</p>
                    <p><strong>Dates:</strong> Q1 2022 ‚Äì Q4 2022</p>
                    <p>The client is the biggest construction and development company in Finland. They specialize in apartments, business premises and entire areas, as well as demanding infrastructure projects and paving. Their annual revenue is over 2.2 billion.</p>
                    <p>The client has several events or objects that lead to a sale, including sales leads and marketing campaigns. They refer to these as ‚Äòopportunities‚Äô. Each month, there are sales targets the client wants to reach. The client wants to know, for a certain sales target at a specific point in time, how many opportunities are needed to reach those targets. This way, they can tailor their marketing and work with their salespeople to ensure they are doing what they can to reach the set sales targets.</p>
                    <p>I was part of a team of two that architected the solution. 
                        I was responsible for the data integration and aggregation, cleaning, validating and transforming the data as a source for the machine learning model. 
                        I also implemented the feature selection and model training. With two months left to go in the project, the other team member ended up leaving the company, leaving me as the only developer. 
                        My contribution was highly valued by the client, as I was still able to deliver the project within the deadline despite the difficult circumstances.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>Time Series Forecasting</span>
                        <span>Machine Learning</span>
                        <span>AI</span>
                        <span>Real Estate</span>
                        <span>Sales</span>
                        <span>Data Transformation</span>
                        <span>Cleaning</span>
                        <span>Validation</span>
                        <span>Aggregation and Integration</span>
                        <span>Seasonality</span>
                    </div>
                </div>

                <!-- Project 5: MLOps Engineer ‚Äì Machine Learning Platform -->
                <div class="project">
                    <h4>MLOps Engineer ‚Äì Machine Learning Platform</h4>
                    <p><strong>Company:</strong> A Construction and Development Company</p>
                    <p><strong>Dates:</strong> Q1 2022 ‚Äì Q4 2022</p>
                    <p>The client is the biggest construction and development company in Finland. They specialize in apartments, business premises and entire areas, as well as demanding infrastructure projects and paving. Their annual revenue is over 2.2 billion.</p>
                    <p>The client wants to be more data driven and have a central platform for Artificial Intelligence and Machine Learning projects. They would like to be able to re-use the same infrastructure and have a system in place that handles model versioning, packaging, monitoring and deployments.</p>
                    <p>I developed the Infrastructure as Code using Terraform to deploy the Azure resources, ensuring that it can be easily maintained across different environments and replicated for other projects. 
                        Then created the CI/CD pipelines used for model training and deployment. This way, all the steps of the training process, including preprocessing, training and inference, could be automated. 
                        Additionally, model versioning and monitoring was automatically integrated with Azure Machine Learning services, and docker images used for packaging and deployments maintained in Azure Container Registry.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>Infrastructure as Code (IaC)</span>
                        <span>CI/CD</span>
                        <span>MLOps</span>
                        <span>Azure DevOps</span>
                        <span>Azure Pipelines</span>
                        <span>Azure Machine Learning</span>
                        <span>Azure Container Registry</span>
                    </div>
                </div>
            </div>


            <div class="job">
                <h3>Machine Learning Engineer, MVision (2021 - 2022)</h3>
                
                <!-- Project 1: Machine Learning Engineer ‚Äì Computer Vision -->
                <div class="project">
                    <h4>Machine Learning Engineer ‚Äì Computer Vision</h4>
                    <p><strong>Company:</strong> A Medical Equipment Manufacturing Company</p>
                    <p><strong>Dates:</strong> Q2 2021 ‚Äì Q4 2021</p>
                    <p>The client is a start-up on the cutting edge of AI tooling in the healthcare sector, operating across 17 countries worldwide.</p>
                    <p>Their flagship product is an AI-powered segmentation tool that helps to standardize contouring and automate it to streamline the radiotherapy treatment planning workflow. Labeling the training data for the model is extremely expensive due to the medical expertise required of the labeler, and the tooling required due to the 3 Dimensionality of the data. The project was to leverage large amounts of unlabeled data to improve the model training process.</p>
                    <p>I worked on an R&D project, in which I created a self-supervised pretraining workflow. This included setting up a preprocessing, pretraining and training pipeline using PyTorch. 
                        I tested out multiple existing self-supervised computer vision techniques, as well as altering them to fit the use case of 3D medical data. 
                        I also tested different combinations and configurations of proxy tasks, such as masking, blurring, and local pixel shuffling. 
                        The final result was a pretraining which was able to improve sample efficiency and training efficiency of the downstream model training. 
                        This meant a lower amount of training data and a lower amount of training cycles needed to achieve a similar result.</p>
                    <div class="project-keywords">
                        <strong>Keywords:</strong>
                        <span>PyTorch</span>
                        <span>Deep Learning</span>
                        <span>Image Segmentation</span>
                        <span>Computer Vision</span>
                        <span>Self-Supervised Learning</span>
                        <span>Medical Data</span>
                        <span>Healthcare</span>
                        <span>Pretraining</span>
                        <span>Sample Efficiency</span>
                        <span>Training Efficiency</span>
                    </div>
                </div>
            </div>
        </section>


    </main>
    <div id="footer-placeholder"></div>
</body>
</html>
